{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23ede0a",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - IMDb Movie Reviews Sentiment Analysis\n",
    "## Introduction\n",
    "This notebook presents an **exploratory data analysis (EDA)** of the IMDb Movie Reviews dataset from Kaggle, as a part of a personal natural language processing project. The goal of this analysis is to perform sentiment classification on movie reviews.\n",
    "\n",
    "**Dataset:** IMDB Dataset of 50K Movie Reviews (Kaggle)\n",
    "\n",
    "**Objective:** Explore and visualize the dataset to gain insights and guide further text preprocessing and modeling\n",
    "\n",
    "**Author:** NGUYEN Ngoc Dang Nguyen - Final-year Student in Computer Science, Aix-Marseille University\n",
    "\n",
    "**Analysis Pipeline:**\n",
    "1. Load and preview the raw dataset\n",
    "2. Dataset overview and basic statistics\n",
    "3. Sentiment distribution analysis\n",
    "4. Text length and word count analysis\n",
    "5. Most frequent words analysis\n",
    "6. Text quality and content inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f00d5e8",
   "metadata": {},
   "source": [
    "## 1. Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6466f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.subplots as sp\n",
    "import re\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import constants from config\n",
    "from config import *\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Data will be loaded from: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da0e81",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDb dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\nColumn names: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd89dd8",
   "metadata": {},
   "source": [
    "## 3. Dataset Overview and Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Total number of reviews: {len(df)}\")\n",
    "print(f\"Number of features: {df.shape[1]}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nDuplicate reviews: {duplicates}\")\n",
    "\n",
    "# Basic text statistics\n",
    "df['review_length'] = df['review'].str.len()\n",
    "df['word_count'] = df['review'].str.split().str.len()\n",
    "\n",
    "print(f\"\\nText Statistics:\")\n",
    "print(f\"Average review length: {df['review_length'].mean():.0f} characters\")\n",
    "print(f\"Average word count: {df['word_count'].mean():.0f} words\")\n",
    "print(f\"Shortest review: {df['review_length'].min()} characters\")\n",
    "print(f\"Longest review: {df['review_length'].max()} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a1cf5",
   "metadata": {},
   "source": [
    "## 4. Sentiment Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc848be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "\n",
    "# Bar plot for sentiment distribution using plotly\n",
    "fig = px.bar(\n",
    "    x=sentiment_counts.index, \n",
    "    y=sentiment_counts.values,\n",
    "    color=sentiment_counts.index,\n",
    "    labels={\"x\": \"Sentiment\", \"y\": \"Count\"},\n",
    "    title=\"Sentiment Distribution in IMDb Dataset\"\n",
    ")\n",
    "fig.update_layout(title_font_size=18)\n",
    "fig.show()\n",
    "\n",
    "# Pie chart for sentiment proportions using plotly\n",
    "fig = px.pie(\n",
    "    values=sentiment_counts.values, \n",
    "    names=sentiment_counts.index,\n",
    "    title=\"Sentiment Distribution (Proportions)\"\n",
    ")\n",
    "fig.update_traces(textinfo='percent+label')\n",
    "fig.update_layout(title_font_size=18)\n",
    "fig.show()\n",
    "\n",
    "# Class balance check\n",
    "print(f\"Sentiment distribution:\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{sentiment}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "balance_ratio = sentiment_counts.max() / sentiment_counts.min()\n",
    "print(f\"\\nClass balance ratio: {balance_ratio:.2f}\")\n",
    "if balance_ratio > 1.5:\n",
    "    print(\"Dataset shows class imbalance\")\n",
    "else:\n",
    "    print(\"Dataset is well-balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde17f43",
   "metadata": {},
   "source": [
    "## 5. Text Length and Word Count Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for text analysis with plotly\n",
    "fig = sp.make_subplots(rows=2, cols=2, \n",
    "                      subplot_titles=['Review Length Distribution (Characters)', \n",
    "                                      'Word Count Distribution',\n",
    "                                      'Review Length by Sentiment', \n",
    "                                      'Word Count by Sentiment'])\n",
    "\n",
    "# Review length distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=df['review_length'], nbinsx=50, marker_color='skyblue', name='Review Length'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_vline(x=df['review_length'].mean(), line_dash=\"dash\", line_color=\"red\",\n",
    "              annotation_text=f\"Mean: {df['review_length'].mean():.0f}\",\n",
    "              annotation_position=\"top right\",\n",
    "              row=1, col=1)\n",
    "\n",
    "# Word count distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=df['word_count'], nbinsx=50, marker_color='lightgreen', name='Word Count'),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_vline(x=df['word_count'].mean(), line_dash=\"dash\", line_color=\"red\",\n",
    "              annotation_text=f\"Mean: {df['word_count'].mean():.0f}\",\n",
    "              annotation_position=\"top right\",\n",
    "              row=1, col=2)\n",
    "\n",
    "# Box plots by sentiment - Review Length\n",
    "fig.add_trace(\n",
    "    go.Box(x=df[df['sentiment']=='positive']['sentiment'], \n",
    "           y=df[df['sentiment']=='positive']['review_length'],\n",
    "           name='Positive', marker_color='green'),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Box(x=df[df['sentiment']=='negative']['sentiment'], \n",
    "           y=df[df['sentiment']=='negative']['review_length'],\n",
    "           name='Negative', marker_color='red'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Box plots by sentiment - Word Count\n",
    "fig.add_trace(\n",
    "    go.Box(x=df[df['sentiment']=='positive']['sentiment'], \n",
    "           y=df[df['sentiment']=='positive']['word_count'],\n",
    "           name='Positive', showlegend=False, marker_color='green'),\n",
    "    row=2, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Box(x=df[df['sentiment']=='negative']['sentiment'], \n",
    "           y=df[df['sentiment']=='negative']['word_count'],\n",
    "           name='Negative', showlegend=False, marker_color='red'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=800, width=1000, \n",
    "                  title_text=\"Text Length and Word Count Analysis\",\n",
    "                  showlegend=False)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Statistical comparison by sentiment\n",
    "print(\"\\nSTATISTICAL COMPARISON BY SENTIMENT\")\n",
    "print(\"=\"*50)\n",
    "sentiment_stats = df.groupby('sentiment').agg({\n",
    "    'review_length': ['mean', 'median', 'std'],\n",
    "    'word_count': ['mean', 'median', 'std']\n",
    "}).round(2)\n",
    "print(sentiment_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad37c5",
   "metadata": {},
   "source": [
    "## 6. Most Frequent Words Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a03f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_basic(text):\n",
    "    \"\"\"Basic text cleaning for word frequency analysis\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Keep only alphabetic characters and spaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def get_word_freq(texts, top_n=20, remove_stopwords=True):\n",
    "    \"\"\"Get word frequency from list of texts\"\"\"\n",
    "    stop_words = set(stopwords.words('english')) if remove_stopwords else set()\n",
    "    \n",
    "    all_words = []\n",
    "    for text in texts:\n",
    "        cleaned = clean_text_basic(text)\n",
    "        words = word_tokenize(cleaned)\n",
    "        words = [word for word in words if len(word) > 2 and word not in stop_words]\n",
    "        all_words.extend(words)\n",
    "    \n",
    "    return Counter(all_words).most_common(top_n)\n",
    "\n",
    "# Overall most frequent words\n",
    "print(\"MOST FREQUENT WORDS ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "overall_freq = get_word_freq(df['review'], top_n=20)\n",
    "print(\"Top 20 most frequent words (excluding stopwords):\")\n",
    "for word, count in overall_freq:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Visualize top words using plotly\n",
    "words, counts = zip(*overall_freq)\n",
    "fig = px.bar(x=list(counts), y=list(words), orientation='h',\n",
    "            title='Top 20 Most Frequent Words',\n",
    "            labels={'x':'Frequency', 'y':'Words'},\n",
    "            color=list(counts),\n",
    "            color_continuous_scale='viridis')\n",
    "fig.update_layout(title_font_size=18)\n",
    "fig.show()\n",
    "\n",
    "# Word frequency by sentiment\n",
    "positive_freq = get_word_freq(df[df['sentiment'] == 'positive']['review'], top_n=15)\n",
    "negative_freq = get_word_freq(df[df['sentiment'] == 'negative']['review'], top_n=15)\n",
    "\n",
    "# Create subplots\n",
    "fig = sp.make_subplots(rows=1, cols=2, \n",
    "                      subplot_titles=['Top 15 Words in Positive Reviews', \n",
    "                                      'Top 15 Words in Negative Reviews'])\n",
    "\n",
    "# Positive sentiment words\n",
    "pos_words, pos_counts = zip(*positive_freq)\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=list(pos_counts),\n",
    "        y=list(pos_words),\n",
    "        orientation='h',\n",
    "        marker=dict(color=list(pos_counts), colorscale='Greens'),\n",
    "        name='Positive'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Negative sentiment words\n",
    "neg_words, neg_counts = zip(*negative_freq)\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=list(neg_counts),\n",
    "        y=list(neg_words),\n",
    "        orientation='h',\n",
    "        marker=dict(color=list(neg_counts), colorscale='Reds'),\n",
    "        name='Negative'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=500, width=1000, \n",
    "                 title_text=\"Word Frequency by Sentiment\",\n",
    "                 showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a04c813",
   "metadata": {},
   "source": [
    "## 7. Word Clouds Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for positive and negative reviews\n",
    "positive_text = ' '.join(df[df['sentiment'] == 'positive']['review'])\n",
    "negative_text = ' '.join(df[df['sentiment'] == 'negative']['review'])\n",
    "\n",
    "# Clean text for word clouds\n",
    "positive_clean = clean_text_basic(positive_text)\n",
    "negative_clean = clean_text_basic(negative_text)\n",
    "\n",
    "# Function to encode the word cloud image for Plotly\n",
    "def get_wordcloud_image(text, colormap='viridis'):\n",
    "    # Generate the word cloud\n",
    "    wc = WordCloud(width=800, height=400, \n",
    "                  background_color='white', \n",
    "                  colormap=colormap,\n",
    "                  stopwords=stopwords.words('english')).generate(text)\n",
    "    \n",
    "    # Convert to image\n",
    "    return wc.to_image()\n",
    "\n",
    "# Create word clouds\n",
    "pos_wordcloud_img = get_wordcloud_image(positive_clean, colormap='Greens')\n",
    "neg_wordcloud_img = get_wordcloud_image(negative_clean, colormap='Reds')\n",
    "\n",
    "# Display using plotly and HTML\n",
    "from IPython.display import display, HTML\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to get image as base64 string\n",
    "def image_to_base64(img):\n",
    "    buffered = BytesIO()\n",
    "    img.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "# Display word clouds\n",
    "html_content = f'''\n",
    "<div style=\"display: flex; flex-direction: row;\">\n",
    "    <div style=\"flex: 1; text-align: center;\">\n",
    "        <h3>Word Cloud - Positive Reviews</h3>\n",
    "        <img src=\"data:image/png;base64,{image_to_base64(pos_wordcloud_img)}\" style=\"max-width: 800px;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 1; text-align: center;\">\n",
    "        <h3>Word Cloud - Negative Reviews</h3>\n",
    "        <img src=\"data:image/png;base64,{image_to_base64(neg_wordcloud_img)}\" style=\"max-width: 800px;\">\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "\n",
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e650aa2d",
   "metadata": {},
   "source": [
    "## 8. Text Quality and Content Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TEXT QUALITY AND CONTENT INSPECTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check for HTML tags\n",
    "html_pattern = r'<.*?>'\n",
    "html_reviews = df['review'].str.contains(html_pattern, regex=True).sum()\n",
    "print(f\"Reviews containing HTML tags: {html_reviews}\")\n",
    "\n",
    "# Show example of review with HTML tags\n",
    "if html_reviews > 0:\n",
    "    sample_html = df[df['review'].str.contains(html_pattern, regex=True)]['review'].iloc[0]\n",
    "    print(f\"\\nExample review with HTML tags:\")\n",
    "    print(sample_html[:500] + \"...\" if len(sample_html) > 500 else sample_html)\n",
    "\n",
    "# Check for very short reviews\n",
    "very_short = df[df['word_count'] < 5]\n",
    "print(f\"\\nVery short reviews (<5 words): {len(very_short)}\")\n",
    "if len(very_short) > 0:\n",
    "    print(\"Examples of very short reviews:\")\n",
    "    for i, review in enumerate(very_short['review'].head(3)):\n",
    "        print(f\"{i+1}. {review}\")\n",
    "\n",
    "# Check for very long reviews\n",
    "very_long = df[df['word_count'] > 1000]\n",
    "print(f\"\\nVery long reviews (>1000 words): {len(very_long)}\")\n",
    "\n",
    "# Special characters analysis\n",
    "special_chars = df['review'].str.contains(r'[^a-zA-Z0-9\\s.,!?;:\\-\\'\\\"]', regex=True).sum()\n",
    "print(f\"\\nReviews with special characters: {special_chars}\")\n",
    "\n",
    "# Percentage of uppercase words\n",
    "def get_uppercase_ratio(text):\n",
    "    words = text.split()\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    uppercase_words = sum(1 for word in words if word.isupper() and len(word) > 1)\n",
    "    return uppercase_words / len(words)\n",
    "\n",
    "df['uppercase_ratio'] = df['review'].apply(get_uppercase_ratio)\n",
    "high_uppercase = df[df['uppercase_ratio'] > 0.1]\n",
    "print(f\"\\nReviews with >10% uppercase words: {len(high_uppercase)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab3b0f7",
   "metadata": {},
   "source": [
    "## 9. Sample Review Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbc710",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SAMPLE REVIEW INSPECTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Display sample reviews\n",
    "def display_sample_reviews(df, sentiment, n_samples=2):\n",
    "    samples = df[df['sentiment'] == sentiment].sample(n_samples, random_state=42)\n",
    "    for i, (idx, row) in enumerate(samples.iterrows(), 1):\n",
    "        print(f\"\\n{sentiment.upper()} Review #{i}:\")\n",
    "        print(f\"Length: {row['review_length']} chars, Words: {row['word_count']}\")\n",
    "        print(\"-\" * 80)\n",
    "        review_preview = row['review'][:400] + \"...\" if len(row['review']) > 400 else row['review']\n",
    "        print(review_preview)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "display_sample_reviews(df, 'positive', 2)\n",
    "display_sample_reviews(df, 'negative', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88058554",
   "metadata": {},
   "source": [
    "## Exploratory Analysis Conclusion\n",
    "The IMDb dataset contains 50,000 well-balanced movie reviews (25k positive, 25k negative) with diverse text lengths and clear sentiment vocabulary patterns. Key preprocessing needs identified: HTML tag removal, text normalization, and outlier handling for extremely long/short reviews.\n",
    "\n",
    "The dataset shows excellent separability between positive and negative sentiments through word frequency analysis and statistical measures. Review lengths range from 7 to 13,704 characters with a healthy median of 1,317, making it suitable for both traditional ML (TF-IDF) and deep learning approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
